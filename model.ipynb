{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyN7ru/Xp6rRTCGOiOjv8+eO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"ic1GZm9f8G17","colab_type":"code","outputId":"62754c4f-9319-440e-8e44-141dd58d81ea","executionInfo":{"status":"ok","timestamp":1586098868009,"user_tz":-330,"elapsed":20346,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import sys\n","# !pip3 install --upgrade --force-reinstall tensorflow-gpu\n","%tensorflow_version 1.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tXMbUJmNaGxL","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E-26sjp4po2","colab_type":"code","outputId":"78eb8dde-e5ec-4f56-b8f7-d68251619be5","executionInfo":{"status":"ok","timestamp":1586098921369,"user_tz":-330,"elapsed":71697,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HehDrB5l4wFS","colab_type":"code","outputId":"6c2e75ec-0784-4e94-b50b-26809a03df84","executionInfo":{"status":"ok","timestamp":1586098922657,"user_tz":-330,"elapsed":1273,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["os.chdir('/content/drive/My Drive/Colab Notebooks/summarization')\n","print(\"We are here: \",os.getcwd())\n","print(os.listdir())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["We are here:  /content/drive/My Drive/Colab Notebooks/summarization\n","['sent', 'summ', 'dailymail.tgz', 'cnn.tgz', 'data_read_test.ipynb', 'glove.6B.300d.txt', 'summ2', 'model.ipynb']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OqQtVVo3J_PP","colab_type":"code","outputId":"184178e0-f24e-41db-bb65-f067c4b74474","executionInfo":{"status":"ok","timestamp":1586098922660,"user_tz":-330,"elapsed":1259,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing.text import Tokenizer\n","tokenizer = Tokenizer(num_words=sys.maxsize)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rMy7rjSrGWbw","colab_type":"code","colab":{}},"source":["#Initializing tokenizer for Vocabulary\n","data1 = open('sent').readlines()\n","data2 = open('summ2').readlines()\n","\n","tokenizer.fit_on_texts(data1)\n","tokenizer.fit_on_texts(data2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GdlFvT9WD_Ly","colab_type":"code","outputId":"c22b6381-ea1e-4eb4-b5d6-08d1c02709e3","executionInfo":{"status":"ok","timestamp":1586098974005,"user_tz":-330,"elapsed":52591,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(data2),len(data1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["92454 92454\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hKnUGqopCetq","colab_type":"code","outputId":"f04187c5-466c-424a-f27e-11a109d5db5a","executionInfo":{"status":"ok","timestamp":1586098974006,"user_tz":-330,"elapsed":52583,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''with open('summ2','w') as f:\n","  bos = \"<BOS> \"\n","  eos = \" <EOS>\"\n","  for i in data2:\n","    i = i.strip()\n","    final = bos + i + eos\n","    f.write(final + '\\n')'''"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'with open(\\'summ2\\',\\'w\\') as f:\\n  bos = \"<BOS> \"\\n  eos = \" <EOS>\"\\n  for i in data2:\\n    i = i.strip()\\n    final = bos + i + eos\\n    f.write(final + \\'\\n\\')'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"mO1aXqeUB0ZS","colab_type":"code","outputId":"c72cb8a9-950f-4fa8-8cc4-6512314abb56","executionInfo":{"status":"ok","timestamp":1586099436641,"user_tz":-330,"elapsed":1025,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dictionary = tokenizer.word_index\n","word2idx = {}\n","idx2word = {}\n","num_encoder_tokens = len(tokenizer.word_index)+1\n","num_decoder_tokens = len(tokenizer.word_index)+1\n","for k, v in dictionary.items():\n","    word2idx[k] = v\n","    idx2word[v] = k\n","print(idx2word[276545])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["sioblooula\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7ieBvrNbQL7r","colab_type":"code","outputId":"8ff3e46e-8fa0-4e2e-9382-f2be1283c287","executionInfo":{"status":"ok","timestamp":1586098978222,"user_tz":-330,"elapsed":56778,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Finding the maximum sequence length\n","MAX_INPUT_LENGTH = max(len(i.split()) for i in data1)\n","print(MAX_INPUT_LENGTH)\n","MAX_TARGET_LENGTH = max(len(j.split()) for j in data2)\n","print(MAX_TARGET_LENGTH)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2009\n","112\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MzxzKvgW5aUm","colab_type":"code","colab":{}},"source":["# Preparing GloVe\n","EMBEDDING_DIM = 300\n","embeddings_index = {}\n","f = open(os.path.join('', 'glove.6B.{}d.txt'.format(EMBEDDING_DIM)))\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyYtXw7v_mm7","colab_type":"code","outputId":"184742a6-ab60-4e8f-8e85-d05d408175ef","executionInfo":{"status":"ok","timestamp":1586110349300,"user_tz":-330,"elapsed":1591,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\"u.s\" in embeddings_index"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"h334j2BOAGpv","colab_type":"code","colab":{}},"source":["#Embedding matrix\n","embedding_matrix = np.zeros((len(tokenizer.word_index)+1, EMBEDDING_DIM),dtype='float32')\n","for word,i in tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","    # Words not found in glove will be zeros\n","        embedding_matrix[i] = embedding_vector"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7qdLF_DClcK","colab_type":"code","outputId":"3790a81f-969f-42fc-ebcf-63d5b1ae627c","executionInfo":{"status":"ok","timestamp":1586099322477,"user_tz":-330,"elapsed":4446,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(embedding_matrix.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(330317, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DOSEEH8UWGRw","colab_type":"code","colab":{}},"source":["from keras.layers import Embedding\n","from keras.layers import Dense, LSTM, Input, concatenate\n","from keras.models import Model\n","# tf.random_uniform = tf.random.uniform\n","# tf.get_default_session = tf.compat.v1.get_default_session\n","batch_size = 64\n","epochs = 100\n","HIDDEN_UNITS_ENC = 256\n","num_samples = 10000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXz4wcOrRFUu","colab_type":"code","outputId":"b13e36d6-b505-422d-df66-e82365c5cadd","executionInfo":{"status":"ok","timestamp":1586099326230,"user_tz":-330,"elapsed":8194,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["encoder_inputs = Input(shape=(MAX_INPUT_LENGTH,), name='encoder_inputs')\n","embedding_layer = Embedding(len(tokenizer.word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n","                            input_length=MAX_INPUT_LENGTH, trainable=False, name='embedding_layer')\n","\n","encoder_rnn = LSTM(units=HIDDEN_UNITS_ENC, return_state=True, dropout=0.5, recurrent_dropout=0.5,name='encoder_lstm')\n","encoder_output, state_h_f, state_c_f = encoder_rnn(embedding_layer(encoder_inputs))\n","encoder_rnn2 = LSTM(units=HIDDEN_UNITS_ENC, return_state=True, dropout=0.5, recurrent_dropout=0.5,\n","go_backwards=True,name='encoder_lstm_backward')\n","encoder_output, state_h_b, state_c_b = encoder_rnn2(embedding_layer(encoder_inputs))\n","\n","state_h = concatenate([state_h_f, state_h_b])\n","state_c = concatenate([state_c_f, state_c_b])\n","\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(MAX_TARGET_LENGTH,), name='decoder_inputs')\n","embedding_layer = Embedding(len(tokenizer.word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n","input_length=MAX_TARGET_LENGTH, trainable=False, name='emb_2')\n","decoder_lstm = LSTM(HIDDEN_UNITS_ENC * 2, return_sequences=False, return_state=True, dropout=0.5,\n","recurrent_dropout=0.5, name='decoder_lstm')\n","decoder_outputs, state_h, state_c = decoder_lstm(embedding_layer(decoder_inputs), initial_state=encoder_states)\n","\n","decoder_dense = Dense(len(tokenizer.word_index) + 1, name='decoder_dense')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TSQcb0kUU0kY","colab_type":"code","outputId":"9750c692-6283-4e90-fdf6-32be3e8357ec","executionInfo":{"status":"ok","timestamp":1586099326231,"user_tz":-330,"elapsed":8193,"user":{"displayName":"VivekP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOkXiXigsCk7MnbNKvnhF75YMgNT2iJnyNpoFt8A=s64","userId":"10402906282562369787"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FGkDjIqRxoSw","colab_type":"code","colab":{}},"source":["#Training and INference\n","model.fit([encoder_input_data,decoder_input_data],decoder_target_data,batch_size = batch_size, epochs = epochs,validation_split=0.2)\n","model.save('s2s.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfU1YGMhqjo_","colab_type":"code","colab":{}},"source":["#inference step\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape = (latent_dim,))\n","decoder_state_input_c = Input(shape = (latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h,decoder_state_input_c]\n","decoder_output, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n","decoder_states = [state_h,state_c]\n","decoder_outputs = decoder_dense(decoder_output)\n","decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BM4OCgHEqo9t","colab_type":"code","colab":{}},"source":["#decoding sequences\n","def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jwQxRtSqvtK","colab_type":"code","colab":{}},"source":["for seq in range(100):\n","  input_seq = encoder_input_data[seq:seq+1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('-')\n","  print('Input sentence:', input_texts[seq])\n","  print('Actual Sentence:', target_texts[seq][1:-1])\n","  print('Decoded sentence:', decoded_sentence)"],"execution_count":0,"outputs":[]}]}